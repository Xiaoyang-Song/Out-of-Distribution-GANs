{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wasserstein Distance Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from dataset import MNIST, CIFAR10\n",
    "from models.mnist_cnn import MNISTCNN\n",
    "from trainer import train\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Training & Validation Datasets \\& Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_tri_set, mnist_val_set, mnist_tri_loader, mnist_val_loader = MNIST(64, 32)\n",
    "cifar_tri_set, cifar_val_set , cifar_tri_loader, cifar_val_loader = MNIST(64, 32)\n",
    "# TODO: Show dataset statistics and sample images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a toy CNN using MNIST\n",
    "We first train a toy CNN model on MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/xiaoyangsong/Desktop/OOD Research/Out-of-Distribution-GANs/notebook.ipynb Cell 6'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000005?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m MNISTCNN()\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000005?line=1'>2</a>\u001b[0m train(model \u001b[39m=\u001b[39;49m model, train_loader\u001b[39m=\u001b[39;49mmnist_tri_loader, val_loader\u001b[39m=\u001b[39;49mmnist_val_loader, num_epoch\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/OOD Research/Out-of-Distribution-GANs/trainer.py:21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, num_epoch)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/trainer.py?line=18'>19</a>\u001b[0m logits \u001b[39m=\u001b[39m model(img)\n\u001b[1;32m     <a href='file:///Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/trainer.py?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, label)\n\u001b[0;32m---> <a href='file:///Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/trainer.py?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='file:///Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/trainer.py?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='file:///Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/trainer.py?line=22'>23</a>\u001b[0m \u001b[39m# Append training statistics\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MNISTCNN().to(DEVICE)\n",
    "train(model = model, train_loader=mnist_tri_loader, val_loader=mnist_val_loader, num_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| test_sample.shape: torch.Size([1, 28, 28])\n",
      "ic| test_softmax.shape: torch.Size([1, 10])\n",
      "ic| test_softmax: tensor([[1.2200e-13, 2.2747e-13, 2.1682e-09, 1.0000e+00, 1.5332e-16, 3.3098e-12,\n",
      "                           2.3926e-20, 2.2021e-10, 1.2905e-08, 5.4976e-08]],\n",
      "                         grad_fn=<SoftmaxBackward0>)\n",
      "ic| pred: tensor([3])\n",
      "ic| test_label: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Sanity Check\n",
    "test_sample, test_label = mnist_tri_set.__getitem__(7)\n",
    "ic(test_sample.shape)\n",
    "test_logits = model(test_sample.unsqueeze(0))\n",
    "test_softmax = torch.softmax(test_logits, dim=-1)\n",
    "ic(test_softmax.shape)\n",
    "pred = torch.argmax(test_logits, dim=1)\n",
    "ic(test_softmax)\n",
    "ic(pred)\n",
    "ic(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wasserstein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_matrix(X, Y):\n",
    "    # TODO: Change this to more generic version\n",
    "    if len(X.shape) == 2:\n",
    "        N,D = X.shape\n",
    "        M,D = Y.shape\n",
    "        return (1 - torch.eye(N, M)).to(DEVICE)\n",
    "    \n",
    "    if len(X.shape) == 3:\n",
    "        B,N,D = X.shape\n",
    "        B,M,D = Y.shape\n",
    "        return torch.unsqueeze(1 - torch.eye(N, M), 0).repeat(B, 1, 1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_2_onehot(label, C, device):\n",
    "    # transform the InD labels into one-hot vector\n",
    "    assert type(label) == torch.Tensor\n",
    "\n",
    "    size = label.shape[0]\n",
    "    if len(label.shape) == 1:\n",
    "        label = torch.unsqueeze(label, 1)\n",
    "    \n",
    "    label = label % C\n",
    "    \n",
    "    label_onehot = torch.FloatTensor(size, C).to(device)\n",
    "\n",
    "    label_onehot.zero_()\n",
    "    label_onehot.scatter_(1, label, 1)\n",
    "    return label_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| test_input.shape: torch.Size([1, 10, 1])\n",
      "ic| test_input[:,:,0].shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "def sink_dist_test(input, target, C, device):\n",
    "    \n",
    "    test_label_onehot = label_2_onehot(target, C, device)\n",
    "    test_label_onehot = torch.unsqueeze(test_label_onehot, -1)\n",
    "    test_input = torch.unsqueeze(input, -1)\n",
    "    ##Loss value for InD samples\n",
    "    test_loss = SamplesLoss(\"sinkhorn\", p=2, blur=1., cost=cost_matrix) #Wasserstein-1 distance\n",
    "    ic(test_input.shape)\n",
    "    ic(test_input[:,:,0].shape)\n",
    "    test_loss_value = test_loss(test_input[:,:,0], test_input, test_label_onehot[:,:,0], test_label_onehot)\n",
    "    \n",
    "    return test_loss_value\n",
    "\n",
    "def sink_dist_test_v2(input, C, device):\n",
    "    \n",
    "    all_class = torch.LongTensor([i for i in range(C)]).to(device)\n",
    "    all_class_onehot = label_2_onehot(all_class, C, device)\n",
    "    ##reshape into (B,N,D)\n",
    "    all_class_onehot = torch.unsqueeze(all_class_onehot, -1)\n",
    "    test_input = torch.unsqueeze(input, -1)\n",
    "    test_batch_size = test_input.shape[0]\n",
    "    test_loss_values = torch.zeros(test_batch_size, C).to(device)\n",
    "    test_loss = SamplesLoss(\"sinkhorn\", p=2, blur=1., cost = cost_matrix) #Wasserstein-1 distance\n",
    "    # ic(test_batch_size)\n",
    "    for b in range(test_batch_size):\n",
    "        input_b = test_input[b:b+1,:,:].repeat(C, 1, 1)\n",
    "        # ic(input_b.shape)\n",
    "        # ic(input_b[:,:,0].shape)\n",
    "        # ic(all_class_onehot.shape)\n",
    "        test_loss_values[b] = test_loss(input_b[:,:,0], input_b, all_class_onehot[:,:,0], all_class_onehot)\n",
    "    \n",
    "    return test_loss_values.min(dim=1)[0]\n",
    "\n",
    "# Sanity Check\n",
    "one_hot_eg = label_2_onehot(torch.tensor([test_label]), 10, DEVICE)\n",
    "sample_wass_loss = sink_dist_test(test_softmax, torch.tensor([test_label]), 10, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| sample_wass_loss: tensor([3.1974e-14], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3.1974e-14], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(sample_wass_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| pred: tensor([5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (100) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/xiaoyangsong/Desktop/OOD Research/Out-of-Distribution-GANs/notebook.ipynb Cell 15'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000014?line=8'>9</a>\u001b[0m ic(pred)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000014?line=9'>10</a>\u001b[0m \u001b[39m# Sanity check for OOD wasserstein distance\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000014?line=10'>11</a>\u001b[0m OOD_wass_loss \u001b[39m=\u001b[39m sink_dist_test_v2(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mOOD_softmax, C\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, device\u001b[39m=\u001b[39;49mDEVICE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000014?line=11'>12</a>\u001b[0m ic(OOD_wass_loss)\n",
      "\u001b[1;32m/Users/xiaoyangsong/Desktop/OOD Research/Out-of-Distribution-GANs/notebook.ipynb Cell 13'\u001b[0m in \u001b[0;36msink_dist_test_v2\u001b[0;34m(input, C, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000012?line=25'>26</a>\u001b[0m     input_b \u001b[39m=\u001b[39m test_input[b:b\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,:,:]\u001b[39m.\u001b[39mrepeat(C, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000012?line=26'>27</a>\u001b[0m     \u001b[39m# ic(input_b.shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000012?line=27'>28</a>\u001b[0m     \u001b[39m# ic(input_b[:,:,0].shape)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000012?line=28'>29</a>\u001b[0m     \u001b[39m# ic(all_class_onehot.shape)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000012?line=29'>30</a>\u001b[0m     test_loss_values[b] \u001b[39m=\u001b[39m test_loss(input_b[:,:,\u001b[39m0\u001b[39;49m], input_b, all_class_onehot[:,:,\u001b[39m0\u001b[39;49m], all_class_onehot)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/notebook.ipynb#ch0000012?line=31'>32</a>\u001b[0m \u001b[39mreturn\u001b[39;00m test_loss_values\u001b[39m.\u001b[39mmin(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py:231\u001b[0m, in \u001b[0;36mSamplesLoss.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py?line=226'>227</a>\u001b[0m     α, x, β, y \u001b[39m=\u001b[39m α\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), x\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), β\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), y\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py?line=229'>230</a>\u001b[0m \u001b[39m# Run --------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py?line=230'>231</a>\u001b[0m values \u001b[39m=\u001b[39m routines[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss][backend]( α, x, β, y, \n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py?line=231'>232</a>\u001b[0m             p \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, blur \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblur, reach \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreach, \n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py?line=232'>233</a>\u001b[0m             diameter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiameter, scaling \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaling, truncate \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtruncate, \n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py?line=233'>234</a>\u001b[0m             cost \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcost, kernel \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel, cluster_scale\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcluster_scale,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py?line=234'>235</a>\u001b[0m             debias \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdebias, potentials \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpotentials,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py?line=235'>236</a>\u001b[0m             labels_x \u001b[39m=\u001b[39;49m l_x, labels_y \u001b[39m=\u001b[39;49m l_y,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py?line=236'>237</a>\u001b[0m             verbose \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose )\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py?line=239'>240</a>\u001b[0m \u001b[39m# Make sure that the output has the correct shape ------------------------------------\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/samples_loss.py?line=240'>241</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpotentials:  \u001b[39m# Return some dual potentials (= test functions) sampled on the input measures\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_samples.py:50\u001b[0m, in \u001b[0;36msinkhorn_tensorized\u001b[0;34m(α, x, β, y, p, blur, reach, diameter, scaling, cost, debias, potentials, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_samples.py?line=44'>45</a>\u001b[0m C_xy, C_yx \u001b[39m=\u001b[39m ( cost( x, y\u001b[39m.\u001b[39mdetach()), cost( y, x\u001b[39m.\u001b[39mdetach()) )  \u001b[39m# (B,N,M), (B,M,N)\u001b[39;00m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_samples.py?line=47'>48</a>\u001b[0m diameter, ε, ε_s, ρ \u001b[39m=\u001b[39m scaling_parameters( x, y, p, blur, reach, diameter, scaling )\n\u001b[0;32m---> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_samples.py?line=49'>50</a>\u001b[0m a_x, b_y, a_y, b_x \u001b[39m=\u001b[39m sinkhorn_loop( softmin_tensorized, \n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_samples.py?line=50'>51</a>\u001b[0m                                     log_weights(α), log_weights(β), \n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_samples.py?line=51'>52</a>\u001b[0m                                     C_xx, C_yy, C_xy, C_yx, ε_s, ρ, debias\u001b[39m=\u001b[39;49mdebias )\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_samples.py?line=53'>54</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sinkhorn_cost(ε, ρ, α, β, a_x, b_y, a_y, b_x, batch\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, debias\u001b[39m=\u001b[39mdebias, potentials\u001b[39m=\u001b[39mpotentials)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_divergence.py:162\u001b[0m, in \u001b[0;36msinkhorn_loop\u001b[0;34m(softmin, α_logs, β_logs, C_xxs, C_yys, C_xys, C_yxs, ε_s, ρ, jumps, kernel_truncation, truncate, cost, extrapolate, debias, last_extrapolation)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_divergence.py?line=159'>160</a>\u001b[0m \u001b[39m# \"Coordinate ascent\" on the dual problems:\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_divergence.py?line=160'>161</a>\u001b[0m \u001b[39mif\u001b[39;00m debias:\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_divergence.py?line=161'>162</a>\u001b[0m     at_x \u001b[39m=\u001b[39m λ \u001b[39m*\u001b[39m softmin(ε, C_xx, α_log \u001b[39m+\u001b[39;49m a_x\u001b[39m/\u001b[39;49mε )  \u001b[39m# OT(α,α)\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_divergence.py?line=162'>163</a>\u001b[0m     bt_y \u001b[39m=\u001b[39m λ \u001b[39m*\u001b[39m softmin(ε, C_yy, β_log \u001b[39m+\u001b[39m b_y\u001b[39m/\u001b[39mε )  \u001b[39m# OT(β,β)\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geomloss/sinkhorn_divergence.py?line=163'>164</a>\u001b[0m at_y \u001b[39m=\u001b[39m λ \u001b[39m*\u001b[39m softmin(ε, C_yx, α_log \u001b[39m+\u001b[39m b_x\u001b[39m/\u001b[39mε )  \u001b[39m# OT(α,β) wrt. a\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "OOD_sample = cifar_tri_set.__getitem__(0)[0].mean(0, keepdim=True)\n",
    "OOD_logits = model(OOD_sample.unsqueeze(0))\n",
    "# ic(OOD_logits.shape)\n",
    "OOD_softmax = torch.softmax(OOD_logits, dim=-1)\n",
    "# ic(OOD_softmax.shape)\n",
    "pred = torch.argmax(OOD_logits, dim=1)\n",
    "# ic(OOD_softmax)\n",
    "ic(pred)\n",
    "# Sanity check for OOD wasserstein distance\n",
    "OOD_wass_loss = sink_dist_test_v2(input=OOD_softmax, C=10, device=DEVICE)\n",
    "ic(OOD_wass_loss)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
