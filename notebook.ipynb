{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wasserstein Distance Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from dataset import MNIST, CIFAR10\n",
    "from models.mnist_cnn import MNISTCNN\n",
    "from trainer import train\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Training & Validation Datasets \\& Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_tri_set, mnist_val_set, mnist_tri_loader, mnist_val_loader = MNIST(64, 32)\n",
    "cifar_tri_set, cifar_val_set , cifar_tri_loader, cifar_val_loader = MNIST(64, 32)\n",
    "# TODO: Show dataset statistics and sample images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a toy CNN using MNIST\n",
    "We first train a toy CNN model on MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTCNN().to(DEVICE)\n",
    "train(model = model, train_loader=mnist_tri_loader, val_loader=mnist_val_loader, num_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wasserstein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_matrix(X, Y):\n",
    "    # TODO: Change this to more generic version\n",
    "    if len(X.shape) == 2:\n",
    "        N,D = X.shape\n",
    "        M,D = Y.shape\n",
    "        return (1 - torch.eye(N, M)).to(DEVICE)\n",
    "    \n",
    "    if len(X.shape) == 3:\n",
    "        B,N,D = X.shape\n",
    "        B,M,D = Y.shape\n",
    "        return torch.unsqueeze(1 - torch.eye(N, M), 0).repeat(B, 1, 1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_2_onehot(label, C, device):\n",
    "    # transform the InD labels into one-hot vector\n",
    "    assert type(label) == torch.Tensor\n",
    "\n",
    "    size = label.shape[0]\n",
    "    if len(label.shape) == 1:\n",
    "        label = torch.unsqueeze(label, 1)\n",
    "    \n",
    "    label = label % C\n",
    "    \n",
    "    label_onehot = torch.FloatTensor(size, C).to(device)\n",
    "\n",
    "    label_onehot.zero_()\n",
    "    label_onehot.scatter_(1, label, 1)\n",
    "    return label_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sink_dist_test(input, target, C, device):\n",
    "    \n",
    "    test_label_onehot = label_2_onehot(target, C, device)\n",
    "    test_label_onehot = torch.unsqueeze(test_label_onehot, -1)\n",
    "    test_input = torch.unsqueeze(input, -1)\n",
    "    ##Loss value for InD samples \n",
    "    #Wasserstein-1 distance\n",
    "    test_loss = SamplesLoss(\"sinkhorn\", p=2, blur=1., cost=cost_matrix)\n",
    "    # ic(test_input.shape)\n",
    "    # ic(test_input[:,:,0].shape)\n",
    "    # ic(test_label_onehot[:,:,0].shape)\n",
    "    # ic(test_label_onehot.shape)\n",
    "    test_loss_value = test_loss(test_input[:,:,0], test_input, test_label_onehot[:,:,0], test_label_onehot)\n",
    "    \n",
    "    return test_loss_value\n",
    "\n",
    "def sink_dist_test_v2(input, C, device):\n",
    "    \n",
    "    all_class = torch.LongTensor([i for i in range(C)]).to(device)\n",
    "    all_class_onehot = label_2_onehot(all_class, C, device)\n",
    "    ##reshape into (B,N,D)\n",
    "    all_class_onehot = torch.unsqueeze(all_class_onehot, -1)\n",
    "    test_input = torch.unsqueeze(input, -1)\n",
    "    test_batch_size = test_input.shape[0]\n",
    "    test_loss_values = torch.zeros(test_batch_size, C).to(device)\n",
    "    # Approximate Wasserstein distance\n",
    "    test_loss = SamplesLoss(\"sinkhorn\", p=2, blur=1., cost = cost_matrix) \n",
    "    # ic(test_batch_size)\n",
    "    for b in range(test_batch_size):\n",
    "        # ic(test_input.shape)\n",
    "        input_b = test_input[b:b+1,:,:].repeat(C, 1, 1)\n",
    "        # ic(input_b.shape)\n",
    "        # ic(input_b[0:1,:,0].shape)\n",
    "        # ic(all_class_onehot[:,:,0].shape)\n",
    "        # ic(all_class_onehot.shape)\n",
    "        # Modified the line below\n",
    "        test_loss_values[b] = torch.tensor([test_loss(input_b[c:c+1,:,0], input_b[c:c+1:,:], all_class_onehot[c:c+1,:,0], \\\n",
    "                                            all_class_onehot[c:c+1:,:]) for c in range(C)])\n",
    "    \n",
    "    return test_loss_values.min(dim=1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wasserstein Distance Toy Example Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Sanity Check\n",
    "def example_wass_loss_ind(img_id_lst):\n",
    "    wass_loss = []\n",
    "    for id in img_id_lst:\n",
    "        test_sample, test_label = mnist_tri_set.__getitem__(id)\n",
    "        # ic(test_sample.shape)\n",
    "        test_logits = model(test_sample.unsqueeze(0))\n",
    "        test_softmax = torch.softmax(test_logits, dim=-1)\n",
    "        # ic(test_softmax.shape)\n",
    "        # pred = torch.argmax(test_logits, dim=1)\n",
    "        # ic(test_softmax)\n",
    "        # ic(pred)\n",
    "        # ic(test_label)\n",
    "        # one_hot_eg = label_2_onehot(torch.tensor([test_label]), 10, DEVICE)\n",
    "        sample_wass_loss = sink_dist_test(test_softmax, torch.tensor([test_label]), 10, DEVICE)\n",
    "        wass_loss.append(sample_wass_loss)\n",
    "    return torch.tensor(wass_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| mnist_tri_set: Dataset MNIST\n",
      "                       Number of datapoints: 60000\n",
      "                       Root location: ./Datasets\n",
      "                       Split: Train\n",
      "                       StandardTransform\n",
      "                   Transform: Compose(\n",
      "                                  ToTensor()\n",
      "                              )\n",
      "ic| cifar_tri_set: Dataset MNIST\n",
      "                       Number of datapoints: 60000\n",
      "                       Root location: ./Datasets\n",
      "                       Split: Train\n",
      "                       StandardTransform\n",
      "                   Transform: Compose(\n",
      "                                  ToTensor()\n",
      "                              )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./Datasets\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(mnist_tri_set)\n",
    "ic(cifar_tri_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| mean_wass_loss: tensor(0.0061)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0061)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_id_lst = torch.randint(low=0, high=60000, size=(2000,))\n",
    "wass_loss_eg = example_wass_loss_ind(img_id_lst)\n",
    "mean_wass_loss = torch.mean(wass_loss_eg)\n",
    "ic(mean_wass_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| mean_wass_loss: tensor(0.0039)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0039)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check\n",
    "def example_wass_loss_ood(img_id_lst):\n",
    "    wass_loss = []\n",
    "    for id in img_id_lst:\n",
    "        OOD_sample = cifar_tri_set.__getitem__(id)[0].mean(0, keepdim=True)\n",
    "        OOD_logits = model(OOD_sample.unsqueeze(0))\n",
    "        # ic(OOD_logits.shape)\n",
    "        OOD_softmax = torch.softmax(OOD_logits, dim=1)\n",
    "        # ic(OOD_softmax.shape)\n",
    "        # pred = torch.argmax(OOD_logits, dim=1)\n",
    "        # ic(OOD_softmax)\n",
    "        # ic(pred)\n",
    "        # Sanity check for OOD wasserstein distance\n",
    "        OOD_wass_loss = sink_dist_test_v2(input=OOD_softmax, C=torch.tensor(10), device=DEVICE)\n",
    "        # ic(OOD_wass_loss)\n",
    "        wass_loss.append(OOD_wass_loss)\n",
    "    return torch.tensor(wass_loss)    \n",
    "        \n",
    "\n",
    "img_id_lst = torch.randint(low=0, high=60000, size=(2000,))\n",
    "wass_loss_eg = example_wass_loss_ood(img_id_lst)\n",
    "mean_wass_loss = torch.mean(wass_loss_eg)\n",
    "ic(mean_wass_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| wass_loss_eg[0:25]: tensor([1.0641e-10, 1.6086e-05, 8.1767e-03, 2.5580e-13, 8.0821e-04, 1.1333e-01,\n",
      "                                1.1584e-05, 9.1160e-08, 6.4926e-05, 2.7420e-07, 2.3192e-11, 3.2685e-13,\n",
      "                                8.7994e-11, 1.3145e-12, 3.7460e-11, 8.5549e-12, 1.6371e-10, 2.7254e-06,\n",
      "                                1.8332e-12, 1.8777e-06, 3.0437e-06, 7.5060e-07, 6.8261e-04, 3.8321e-07,\n",
      "                                1.6147e-06])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0641e-10, 1.6086e-05, 8.1767e-03, 2.5580e-13, 8.0821e-04, 1.1333e-01,\n",
       "        1.1584e-05, 9.1160e-08, 6.4926e-05, 2.7420e-07, 2.3192e-11, 3.2685e-13,\n",
       "        8.7994e-11, 1.3145e-12, 3.7460e-11, 8.5549e-12, 1.6371e-10, 2.7254e-06,\n",
       "        1.8332e-12, 1.8777e-06, 3.0437e-06, 7.5060e-07, 6.8261e-04, 3.8321e-07,\n",
       "        1.6147e-06])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
