{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from config import *\n",
    "from dataset import *\n",
    "import umap\n",
    "import umap.plot\n",
    "from trainers.adv_g import *\n",
    "from trainers.trainer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OoD Generation via Adversarial Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 128\n",
    "val_B = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_tri_set, mnist_val_set, mnist_tri_loader, mnist_val_loader = MNIST(B, 32, 2, True)\n",
    "# cifar_tri_set, cifar_val_set , cifar_tri_loader, cifar_val_loader = CIFAR10(B, 32)\n",
    "# USE MNIST SUBSAMPLES\n",
    "ind_idx = [0,2,3,6,8]\n",
    "ood_idx = [1,7]\n",
    "# TODO: Use classifier on 1,4,5,7,9, check wass loss\n",
    "# test_idx = [4,5,9]\n",
    "mnist_dset_dict = MNIST_SUB(batch_size=B, val_batch_size=val_B, idx_ind=ind_idx, idx_ood=ood_idx, shuffle=True)\n",
    "# TODO: Show dataset statistics and sample images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrain discriminator (i.e. classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| f\"Learning rate = {1e-4}\": 'Learning rate = 0.0001'\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  # 1 | training loss: 0.5934966845765646               | training acc: 0.8551825612219137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:26<00:52, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  # 1 | validation loss: 0.13500042020892486               | validation acc: 0.9577323717948718\n",
      "Epoch  # 2 | training loss: 0.11685005640970791               | training acc: 0.9635694111335522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:52<00:26, 26.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  # 2 | validation loss: 0.07462152342001598               | validation acc: 0.9742665187376727\n",
      "Epoch  # 3 | training loss: 0.07501827731584658               | training acc: 0.9769478982580156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:18<00:00, 26.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  # 3 | validation loss: 0.05083613257067135               | validation acc: 0.9822793392504932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_info = {'H':28,'W':28,'C':1}\n",
    "D = dc_discriminator(img_info, GAN_TYPE.OOD).to(DEVICE)\n",
    "ind_train_loader = mnist_dset_dict['train_set_ind_loader']\n",
    "ind_val_loader = mnist_dset_dict['val_set_ind_loader']\n",
    "train(D,ind_train_loader,ind_val_loader, num_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save/Load pretrained discriminator (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../checkpoint/adv_pre_D.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model_state_dict': D.state_dict()}, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained D state is loaded from ../checkpoint/adv_pre_D.pt.\n"
     ]
    }
   ],
   "source": [
    "pretrain = torch.load(path)\n",
    "D.load_state_dict(pretrain['model_state_dict'])\n",
    "print(f\"Pretrained D state is loaded from {path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100 # B * M is the number of samples we want\n",
    "nl_Wt = 1.5 # Negative log of Wasserstein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = adv_generation(ind_tri_loader, D, B, M, nl_Wt)\n",
    "torch.save(img, '../checkpoint/adv_g_img.pt')\n",
    "# img: BM x 1 x 28 x 28 for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.load('../checkpoint/adv_g_img.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-Distribution vs. Generated OoD (Verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x_ind.shape: torch.Size([29781, 784])\n",
      "ic| x_ind_y.shape: torch.Size([29781])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([29781])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ind = mnist_dset_dict['train_set_ind']\n",
    "x_ind_y = torch.tensor([x[1] for x in x_ind]) # All y labels\n",
    "x_ind = torch.stack([x[0].flatten() for x in x_ind]) # All images\n",
    "y_ind = torch.ones((len(x_ind))) # All ones for in-distribution samples\n",
    "ic(x_ind.shape)\n",
    "ic(x_ind_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_g = img.flatten(1,3)\n",
    "y_g = torch.ones(x_g.shape[0], dtype=torch.int) * -1\n",
    "ic(x_g.shape)\n",
    "ic(y_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x_ood.shape: torch.Size([13007, 784])\n",
      "ic| x_ood_y.shape: torch.Size([13007])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([13007])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ood = mnist_dset_dict['train_set_ood']\n",
    "x_ood_y = torch.tensor([x[1] for x in x_ood])\n",
    "x_ood = torch.stack([x[0].flatten() for x in x_ood])\n",
    "ic(x_ood.shape)\n",
    "ic(x_ood_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vis = torch.cat((x_ood, x_g, x_ind),dim=0)\n",
    "y_vis = torch.cat((x_ood_y, y_g, x_ind_y), dim=0)\n",
    "ic(x_vis.shape)\n",
    "ic(y_vis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_visualization(x_vis, y_vis)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
