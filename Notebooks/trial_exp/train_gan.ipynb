{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are we using Colab now? False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "print(f\"Are we using Colab now? {IN_COLAB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "from icecream import ic\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time, os\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"Out-of-Distribution-GANs\"\n",
    "    GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
    "    print(os.listdir(GOOGLE_DRIVE_PATH))\n",
    "    sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "    %pip install icecream tensorboard\n",
    "    %pip install umap-learn pandas matplotlib datashader bokeh holoviews colorcet scikit-image\n",
    "else:\n",
    "#     ic(sys.prefix)\n",
    "#     ic(sys.path)\n",
    "#     pass\n",
    "    # ic(sys.path)\n",
    "    sys.path.insert(0, '../../')\n",
    "os.environ[\"TZ\"] = \"US/Eastern\"\n",
    "time.tzset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from dataset import MNIST,CIFAR10, MNIST_SUB, SVHN\n",
    "# from models.mnist_cnn import MNISTCNN\n",
    "from models.hparam import HParam\n",
    "from models.gans import *\n",
    "from models.dc_gan_model import *\n",
    "from utils import *\n",
    "from models.ood_gan_backbone import *\n",
    "from ood_gan import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Using downloaded and verified file: ./Datasets/SVHN/train_32x32.mat\n",
      "Using downloaded and verified file: ./Datasets/SVHN/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| ood_img_batch.shape: torch.Size([64, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsz_tri, bsz_val = 256, 128\n",
    "cifartri_set, cifarval_set, cifar_tri_loader, cifar_val_loader = CIFAR10(bsz_tri, bsz_val)\n",
    "\n",
    "ood_bsz_tri = 64\n",
    "ood_bsz_val = 128\n",
    "svhn_tri_set, svhn_val_set, svhn_triloader, svhn_valloader = SVHN(ood_bsz_tri, ood_bsz_val)\n",
    "ood_img_batch, ood_img_label = next(iter(svhn_triloader))\n",
    "ic(ood_img_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4b96141db34d619d87bc21ae5c657e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/xiaoyangsong/Desktop/OOD Research/Out-of-Distribution-GANs/Notebooks/Latest/train_gan.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/Notebooks/Latest/train_gan.ipynb#ch0000015?line=19'>20</a>\u001b[0m logits \u001b[39m=\u001b[39m model(img)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/Notebooks/Latest/train_gan.ipynb#ch0000015?line=20'>21</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, label)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/Notebooks/Latest/train_gan.ipynb#ch0000015?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/Notebooks/Latest/train_gan.ipynb#ch0000015?line=22'>23</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/OOD%20Research/Out-of-Distribution-GANs/Notebooks/Latest/train_gan.ipynb#ch0000015?line=23'>24</a>\u001b[0m \u001b[39m# Append training statistics\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=386'>387</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=387'>388</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=388'>389</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=389'>390</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=393'>394</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=394'>395</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py?line=395'>396</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "D = Discriminator()\n",
    "pretrain_writer = SummaryWriter(\"PreTrain\")\n",
    "model = D\n",
    "if IN_COLAB:\n",
    "    pretrain_addr = GOOGLE_DRIVE_PATH + '/checkpoint/CIFAR-SVHN/pretrainedD.pt'\n",
    "else:\n",
    "    pretrain_addr = 'checkpoint/CIFAR-SVHN/pretrainedD.pt'\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epoch=8\n",
    "# Simple training loop\n",
    "iter_count_train = 0\n",
    "iter_count_val = 0\n",
    "for epoch in tqdm(range(num_epoch)):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss, train_acc = [], []\n",
    "    for idx, (img, label) in enumerate(cifar_tri_loader):\n",
    "        img = img.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(img)\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Append training statistics\n",
    "        acc = (torch.argmax(logits, dim=1) == label).sum().item() / label.shape[0]\n",
    "        train_acc.append(acc)\n",
    "        train_loss.append(loss.detach().item())\n",
    "        pretrain_writer.add_scalar(\"Training/Accuracy\", acc, iter_count_train)\n",
    "        pretrain_writer.add_scalar(\"Training/Loss\", loss.detach().item(), iter_count_train)\n",
    "        iter_count_train += 1\n",
    "\n",
    "    pretrain_writer.add_scalar(\"Training/Accuracy (Epoch)\", np.mean(train_acc), epoch)\n",
    "    pretrain_writer.add_scalar(\"Training/Loss (Epoch)\", np.mean(train_loss), epoch)\n",
    "    print(f\"Epoch  # {epoch + 1} | training loss: {np.mean(train_loss)} \\\n",
    "            | training acc: {np.mean(train_acc)}\")\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_acc = [], []\n",
    "        for idx, (img, label) in enumerate(cifar_val_loader):\n",
    "            img, label = img.to(DEVICE), label.to(DEVICE)\n",
    "            logits = model(img)\n",
    "            loss = criterion(logits, label)\n",
    "            acc = (torch.argmax(logits, dim=1) == label).sum().item() / label.shape[0]\n",
    "            val_acc.append(acc)\n",
    "            val_loss.append(loss.detach().item())\n",
    "            pretrain_writer.add_scalar(\"Training/Accuracy\", acc, iter_count_val)\n",
    "            pretrain_writer.add_scalar(\"Training/Loss\", loss.detach().item(), iter_count_val)\n",
    "            iter_count_val += 1\n",
    "\n",
    "        pretrain_writer.add_scalar(\"Training/Accuracy (Epoch)\", np.mean(val_acc), epoch)\n",
    "        pretrain_writer.add_scalar(\"Training/Loss (Epoch)\", np.mean(val_loss), epoch)\n",
    "        print(f\"Epoch  # {epoch + 1} | validation loss: {np.mean(val_loss)} \\\n",
    "            | validation acc: {np.mean(val_acc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    ckpt_dir = GOOGLE_DRIVE_PATH + '/checkpoint/CIFAR-SVHN/'\n",
    "else:\n",
    "    ckpt_dir = 'checkpoint/CIFAR-SVHN/'\n",
    "\n",
    "ckpt_name = f'CIFAR-SVHN[{ood_bsz_tri}]'\n",
    "hp = HParam(ce=1,wass=0.1, dist=0.8)\n",
    "max_epoch = 1\n",
    "writer_name = ckpt_name\n",
    "n_steps_log = 1\n",
    "noise_dim=96\n",
    "# Model setup\n",
    "D = Discriminator()\n",
    "G = Generator(noise_dim)\n",
    "D_solver = torch.optim.Adam(D.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "G_solver = torch.optim.Adam(G.parameters(), lr=1e-3, betas=(0.5, 0.999))\n",
    "# Training dataset\n",
    "ind_loader = cifar_tri_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = OOD_GAN_TRAINER(D=D, G=G, \n",
    "                        noise_dim=noise_dim, \n",
    "                        bsz_tri=bsz_tri, \n",
    "                        gd_steps_ratio=1, \n",
    "                        hp=hp, \n",
    "                        max_epochs=max_epoch, \n",
    "                        writer_name=writer_name, \n",
    "                        ckpt_name=ckpt_name,\n",
    "                        ckpt_dir=ckpt_dir, \n",
    "                        n_steps_log=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(ind_loader, ood_img_batch, D_solver, G_solver, pretrainedD=None, checkpoint=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
